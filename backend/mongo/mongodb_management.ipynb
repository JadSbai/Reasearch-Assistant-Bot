{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "\n",
    "uri = \"mongodb+srv://Jad:Lifesgood05$@cluster0.y4bz1mr.mongodb.net/?retryWrites=true&w=majority\"\n",
    "\n",
    "# Create a new client and connect to the server\n",
    "client = MongoClient(uri, server_api=ServerApi('1'))\n",
    "\n",
    "# Send a ping to confirm a successful connection\n",
    "try:\n",
    "    client.admin.command('ping')\n",
    "    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "outputs": [],
   "source": [
    "db = client['ResearchAssistant']\n",
    "papers_collection = db['papers']\n",
    "paragraphs_collection = db['paragraphs']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T01:50:23.531979Z",
     "start_time": "2023-11-23T01:50:23.523660Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bson import binary\n",
    "\n",
    "\n",
    "def insert_paper(title, filepath, plaintext, author):\n",
    "    # This function inserts a chapter and returns its ObjectId\n",
    "    # Read PDF file in binary mode\n",
    "    with open(filepath, \"rb\") as file:\n",
    "        binary_data = file.read()\n",
    "    paper = {\n",
    "    \"title\": title,\n",
    "    \"content\": binary.Binary(binary_data),\n",
    "    \"plaintext\": plaintext,\n",
    "    \"author\": author,\n",
    "    }\n",
    "    return papers_collection.insert_one(paper).inserted_id\n",
    "\n",
    "def insert_paragraph(paper_id, text, section_name, previous_paragraph_id=None):\n",
    "    # This function inserts a paragraph and returns its ObjectId\n",
    "    paragraph = {\n",
    "        'text': text,\n",
    "        'section': section_name,\n",
    "        'previous_paragraph': previous_paragraph_id,\n",
    "        'next_paragraph': None,\n",
    "        'paper': paper_id,\n",
    "    }\n",
    "    return paragraphs_collection.insert_one(paragraph).inserted_id\n",
    "\n",
    "def update_paragraph_next(prev_paragraph_id, next_paragraph_id):\n",
    "    # This function updates the 'next_paragraph' field of the previous paragraph\n",
    "    paragraphs_collection.update_one(\n",
    "        {'_id': prev_paragraph_id},\n",
    "        {'$set': {'next_paragraph': next_paragraph_id}}\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "outputs": [],
   "source": [
    "import PyPDF4\n",
    "import fitz\n",
    "def is_likely_section_title(line):\n",
    "    # Pattern to match section titles like '1INTRODUCTION', '2METHODS', etc.\n",
    "    pattern = re.compile(r'^\\d+\\s*[A-Z].*')\n",
    "    return pattern.match(line) or line == 'ABSTRACT' or line == 'REFERENCES'\n",
    "\n",
    "\n",
    "def is_new_paragraph(line, previous_line):\n",
    "    # Check if the previous line ends with a period and the current line starts with an uppercase letter\n",
    "    return previous_line.strip().endswith('.') and line.strip() and line.strip()[0].isupper()\n",
    "\n",
    "def extract_text_with_sections(pdf_path):\n",
    "    document = fitz.open(pdf_path)\n",
    "    sections = {}\n",
    "    current_section = None\n",
    "    current_paragraph = \"\"\n",
    "\n",
    "    for page in document:\n",
    "        # Dimensions of the page\n",
    "        page_height = page.rect.height\n",
    "        header_threshold = page_height * 0.1  # Top 10% for header\n",
    "        footer_threshold = page_height * 0.95  # Bottom 10% for footer\n",
    "        try:\n",
    "            # Attempt to find tables on the page\n",
    "            tables = page.find_tables()\n",
    "            table_bboxes = [fitz.Rect(table.bbox) for table in tables if table]\n",
    "        except Exception as e:\n",
    "            # Handle exceptions and continue processing the rest of the document\n",
    "            print(f\"Error processing tables on page {page.number}: {e}\")\n",
    "            table_bboxes = []\n",
    "        blocks = page.get_text(\"blocks\")\n",
    "        blocks.sort(key=lambda block: (block[1], block[0]))  # Sort by y0, then x0\n",
    "\n",
    "        for block in blocks:\n",
    "            x0, y0, x1, y1, text, block_type, block_no = block\n",
    "            text = text.strip()\n",
    "            word_counts = len(text.split())\n",
    "            \n",
    "            # Exclude headers and footers\n",
    "            if y0 < header_threshold or y1 > footer_threshold:\n",
    "                continue\n",
    "            # Check if block is within any table bbox\n",
    "            block_bbox = fitz.Rect(block[:4])\n",
    "            if any(table_bbox.intersects(block_bbox) for table_bbox in table_bboxes):\n",
    "                continue  # Skip this block as it's part of a table\n",
    "\n",
    "\n",
    "            if is_likely_section_title(text):\n",
    "                current_section = text\n",
    "                sections[current_section] = []\n",
    "            elif current_section and word_counts >= 20:\n",
    "                sections[current_section].append(text)\n",
    "                \n",
    "                \n",
    "            \n",
    "\n",
    "    document.close()\n",
    "    return sections\n",
    "\n",
    "\n",
    "def extract_title_and_authors(pdf_path):\n",
    "    document = fitz.open(pdf_path)\n",
    "    first_page = document[0]\n",
    "    blocks = first_page.get_text(\"blocks\")\n",
    "    blocks.sort(key=lambda block: (block[1], block[0]))  # Sort by y0, then x0\n",
    "\n",
    "    # Identify the header region (e.g., top 10% of the page)\n",
    "    header_threshold = first_page.rect.height * 0.1\n",
    "\n",
    "    title, authors = None, None\n",
    "    for _, y0, _, _, text, _, _ in blocks:\n",
    "        if y0 < header_threshold:\n",
    "            continue  # Skip header\n",
    "        if 'ABSTRACT' in text.upper():\n",
    "            break  # Stop at the ABSTRACT section\n",
    "        if not title and len(text.split()) > 5:\n",
    "            title = text\n",
    "        elif title and not authors:\n",
    "            authors = text\n",
    "        elif authors:\n",
    "            authors += text  # Stop at the next section\n",
    "\n",
    "    document.close()\n",
    "    return title, authors\n",
    "\n",
    "# Example usage\n",
    "\n",
    "\n",
    "\n",
    "# def insert_and_process_pdf(pdf_path, title, author):\n",
    "#     # Insert the whole paper\n",
    "#     sections, plain_text = extract_text_with_sections(pdf_path)\n",
    "#     paper_id = insert_paper(title, pdf_path, plain_text, author)\n",
    "# \n",
    "#     # Iterate over sections and paragraphs, inserting each paragraph\n",
    "#     prev_paragraph_id = None\n",
    "#     for section, paragraphs in sections.items():\n",
    "#         for paragraph_text in paragraphs:\n",
    "#             paragraph_id = insert_paragraph(paper_id, paragraph_text, section, prev_paragraph_id)\n",
    "#             if prev_paragraph_id is not None:\n",
    "#                 update_paragraph_next(prev_paragraph_id, paragraph_id)\n",
    "#             prev_paragraph_id = paragraph_id"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T04:18:00.244603Z",
     "start_time": "2023-11-23T04:18:00.235790Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Table-GPT: Table-tuned GPT for Diverse Table Tasks\n",
      "\n",
      "Authors: Peng Li†, Yeye He‡, Dror Yashar, Weiwei Cui, Song Ge, Haidong Zhang,\n",
      "Danielle Rifinski Fainman, Dongmei Zhang, Surajit Chaudhuri\n",
      "Microsoft Corporation\n",
      "<image: DeviceRGB, width: 1961, height: 814, bpc: 8>\n"
     ]
    }
   ],
   "source": [
    "pdf_path = \"papers/tableGPT.pdf\"\n",
    "title, authors = extract_title_and_authors(pdf_path)\n",
    "print(\"Title:\", title)\n",
    "print(\"Authors:\", authors)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T04:19:20.459791Z",
     "start_time": "2023-11-23T04:19:20.447620Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['ABSTRACT', 'INTRODUCTION', 'THE CLAIRVOYANCE PIPELINE', 'RELATED WORK', 'ILLUSTRATIVE EXAMPLES', 'CONCLUSION'])\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "pdf_path = \"papers/clairvoyance.pdf\"\n",
    "sections = extract_text_with_sections(pdf_path)\n",
    "\n",
    "cleaned_sections = {}\n",
    "for section in sections:\n",
    "    # Remove digits and newline characters\n",
    "    clean_title = re.sub(r'\\d+\\n', '', section)\n",
    "    if clean_title != \"REFERENCES\":\n",
    "        cleaned_sections[clean_title] = sections[section]\n",
    "\n",
    "print(cleaned_sections.keys())\n",
    "# print(cleaned_sections['EXPERIMENTS'])\n",
    "# papers_collection.delete_many({})\n",
    "# paragraphs_collection.delete_many({})\n",
    "# insert_and_process_pdf(pdf_path, \"Table GPT\", \"Jane Smith\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T02:01:35.694497Z",
     "start_time": "2023-11-23T02:01:31.931267Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['ABSTRACT', 'INTRODUCTION', 'THE CLAIRVOYANCE PIPELINE', 'RELATED WORK', 'ILLUSTRATIVE EXAMPLES', 'CONCLUSION', 'REFERENCES'])\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(cleaned_sections.keys())\n",
    "print(len(cleaned_sections['RELATED WORK']))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T01:39:56.557348Z",
     "start_time": "2023-11-23T01:39:56.550033Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "outputs": [
    {
     "data": {
      "text/plain": "DeleteResult({'n': 2699, 'electionId': ObjectId('7fffffff000000000000003d'), 'opTime': {'ts': Timestamp(1700723755, 2725), 't': 61}, 'ok': 1.0, '$clusterTime': {'clusterTime': Timestamp(1700723755, 2725), 'signature': {'hash': b'O\\x1fa\\xcc\\xd1\\xf0H\\x184f\\xf6\\x82\\x03`c\\xd4\\xe6G\\x92\\xdf', 'keyId': 7252338727844839425}}, 'operationTime': Timestamp(1700723755, 2725)}, acknowledged=True)"
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db[\"papers\"].delete_many({})\n",
    "\n",
    "# Delete all documents in the 'paragraphs' collection\n",
    "db[\"paragraphs\"].delete_many({})\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T07:15:55.679185Z",
     "start_time": "2023-11-23T07:15:54.967858Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
